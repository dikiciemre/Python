{\rtf1\ansi\ansicpg1254\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red251\green0\blue7;\red0\green0\blue0;\red251\green0\blue7;
}
{\*\expandedcolortbl;;\cssrgb\c100000\c12195\c0;\cssrgb\c0\c0\c0;\cssrgb\c100000\c12195\c0;
}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs28 \cf0 \
Reinforcement Learning (RL), makine \'f6\uc0\u287 renimi alan\u305 nda bir alt dal olan \'f6\u287 renme t\'fcr\'fcd\'fcr ve \'f6zellikle karar alma ve kontrol problemleri i\'e7in kullan\u305 l\u305 r. RL, bir ajan\u305 n belirli bir \'e7evre i\'e7inde bir dizi eylem ger\'e7ekle\u351 tirerek bir hedefi (\'f6rne\u287 in, bir \'f6d\'fcl\'fc) maksimize etmeye \'e7al\u305 \u351 t\u305 \u287 \u305  bir \'f6\u287 renme paradigmas\u305 d\u305 r. Temel amac\u305 , ajan\u305 n deneyim yoluyla \'e7evresiyle etkile\u351 imde bulunarak en iyi eylemleri \'f6\u287 renmesini sa\u287 lamakt\u305 r.\
\
Reinforcement Learning'de ana bile\uc0\u351 enler \u351 unlard\u305 r:\
\
1. Ajan (Agent): Bu, \'f6\uc0\u287 renme g\'f6revini ger\'e7ekle\u351 tiren ve \'e7evre ile etkile\u351 imde bulunan yapay zeka veya robot gibi bir varl\u305 \u287 \u305  temsil eder. Ajan, belirli bir \'e7evrede farkl\u305  eylemleri ger\'e7ekle\u351 tirir.\
\
2. \'c7evre (Environment): Ajan\uc0\u305 n etkile\u351 imde bulundu\u287 u d\u305 \u351 sal d\'fcnya veya sim\'fclasyonu temsil eder. \'c7evre, ajan\u305 n eylemlerine yan\u305 t verir ve ajan\u305 n bu yan\u305 tlar \'fczerinden \'f6\u287 renmesini sa\u287 lar.\
\
3. Durum (State): Durum, \'e7evrenin anl\uc0\u305 k durumunu veya ajan\u305 n konumunu, g\'f6zlemledi\u287 i bilgileri temsil eder. Ajan, \'e7evre durumunu g\'f6zlemleyerek kararlar\u305 n\u305  verir.\
\
4. Eylem (Action): Ajan\uc0\u305 n \'e7evreye m\'fcdahale etti\u287 i veya tepki g\'f6sterdi\u287 i \u351 eydir. Ajan, mevcut durumuna g\'f6re bir eylem se\'e7er.\
\
5. \'d6d\'fcl (Reward): \'d6d\'fcl, ajan\uc0\u305 n performans\u305 n\u305  de\u287 erlendirmek ve motive etmek i\'e7in kullan\u305 lan anl\u305 k geri bildirimdir. Ajan\u305 n hedefi, zaman i\'e7inde toplam \'f6d\'fcl\'fc maksimize etmektir.\
\
Reinforcement Learning, ajan\uc0\u305 n deneyim yoluyla \'f6\u287 renmesini sa\u287 lar. Ajan, \'e7evreyle etkile\u351 imde bulunarak eylem stratejilerini geli\u351 tirir. Bu s\'fcre\'e7, ajan\u305 n hangi eylemlerin daha fazla \'f6d\'fcl getirdi\u287 ini \'f6\u287 renmesini i\'e7erir. \'d6\u287 renme s\'fcreci genellikle bir dizi deneme ve hata ile ger\'e7ekle\u351 ir.\
\
RL algoritmalar\uc0\u305 , ajan\u305 n en iyi eylemleri nas\u305 l se\'e7ece\u287 ini belirlemek i\'e7in \'e7e\u351 itli stratejiler ve politikalar geli\u351 tirirler. Bu stratejiler, ajan\u305 n durumunu ve ge\'e7mi\u351  deneyimlerini kullanarak en iyi eylemi tahmin etmeye \'e7al\u305 \u351 \u305 r. Pop\'fcler RL algoritmalar\u305  aras\u305 nda Q-Learning, Deep Q-Networks (DQN), Policy Gradient, ve Proximal Policy Optimization (PPO) gibi y\'f6ntemler bulunmaktad\u305 r.\
\
Reinforcement Learning, oyun oynama, robot kontrol\'fc, otomatik ara\'e7lar, finansal ticaret, sa\uc0\u287 l\u305 k bak\u305 m\u305  ve daha bir\'e7ok uygulama alan\u305 nda kullan\u305 lmaktad\u305 r.\
\
\
\
\
\

\fs36 \cf2 A/B TEST\
\

\fs28 \cf3 Diyelim ki bir e-ticaret \uc0\u351 irketi, web sitesindeki "Sat\u305 n Al" d\'fc\u287 mesinin renginin m\'fc\u351 teri sat\u305 n alma davran\u305 \u351 \u305 n\u305  nas\u305 l etkiledi\u287 ini de\u287 erlendirmek istiyor. \u350 irket, mevcut d\'fc\u287 menin rengi olan maviyi de\u287 i\u351 tirmeyi d\'fc\u351 \'fcn\'fcyor ve bunun sat\u305 n alma oranlar\u305 n\u305  art\u305 r\u305 p art\u305 rmayaca\u287 \u305 n\u305  g\'f6rmek istiyor.\
\
\uc0\u304 \u351 te A/B testinin nas\u305 l uyguland\u305 \u287 \u305 n\u305  g\'f6steren ad\u305 mlar:\
\
1. **Hipotez Olu\uc0\u351 turma:** \u350 irketin hipotezi \u351 u olabilir: "Mavi renkli 'Sat\u305 n Al' d\'fc\u287 mesi, sat\u305 n alma i\u351 lemini art\u305 rabilir."\
\
2. **Gruplar\uc0\u305 n Olu\u351 turulmas\u305 :** A/B testi i\'e7in iki grup olu\u351 turulur:\
   - A Grubu (Kontrol Grubu): Bu grup, mevcut web sitesi tasar\uc0\u305 m\u305 n\u305  (mavi d\'fc\u287 me) temsil eder. Bu grup, de\u287 i\u351 iklik yap\u305 lmadan b\u305 rak\u305 l\u305 r.\
   - B Grubu (Deneme Grubu): Bu grup, yeni tasar\uc0\u305 m\u305  temsil eder. Bu grup i\'e7in "Sat\u305 n Al" d\'fc\u287 mesinin rengi ye\u351 ile de\u287 i\u351 tirilir.\
\
3. **Test Uygulamas\uc0\u305 :** Mavi d\'fc\u287 melere sahip olan A grubu ve ye\u351 il d\'fc\u287 melere sahip olan B grubu i\'e7in de\u287 i\u351 iklikler yap\u305 l\u305 r ve web sitesine uygulan\u305 r.\
\
4. **\'d6l\'e7\'fcm ve Veri Toplama:** Her iki grup i\'e7in, "Sat\uc0\u305 n Al" d\'fc\u287 mesine ne kadar s\u305 kl\u305 kla t\u305 kland\u305 \u287 \u305 n\u305  ve ger\'e7ekten sat\u305 n alma i\u351 lemi yapma oranlar\u305 n\u305  izlemeye ba\u351 lay\u305 n. Bu verileri toplamak i\'e7in bir analitik ara\'e7 kullanabilirsiniz.\
\
5. **\uc0\u304 statistiksel Analiz:** Toplanan verileri analiz edin ve her iki grup aras\u305 ndaki farkl\u305 l\u305 klar\u305  de\u287 erlendirmek i\'e7in istatistiksel testler kullan\u305 n. Bu, ye\u351 il d\'fc\u287 meli B grubunun mavi d\'fc\u287 melere g\'f6re daha fazla sat\u305 n alma i\u351 lemi yap\u305 l\u305 p yapmad\u305 \u287 \u305 n\u305  belirlemenize yard\u305 mc\u305  olur.\
\
6. **Sonu\'e7lar\uc0\u305 n De\u287 erlendirilmesi:** Analiz sonu\'e7lar\u305 na dayal\u305  olarak, hipoteziniz do\u287 rulanm\u305 \u351  veya reddedilmi\u351  olacakt\u305 r. \'d6rne\u287 in, B grubunun daha fazla sat\u305 n alma i\u351 lemi yapt\u305 \u287 \u305  g\'f6r\'fcl\'fcrse, ye\u351 il d\'fc\u287 meyi kullanmak daha etkili olabilir ve bu de\u287 i\u351 ikli\u287 i web sitesine uygulamak mant\u305 kl\u305  olabilir.\
\
Bu \'f6rnekte A/B testi, bir de\uc0\u287 i\u351 ikli\u287 in (d\'fc\u287 me rengi) m\'fc\u351 teri davran\u305 \u351 \u305  \'fczerindeki etkisini de\u287 erlendirmek i\'e7in kullan\u305 lm\u305 \u351 t\u305 r. Bu t\'fcr testler, i\u351 letmelerin web sitelerini, \'fcr\'fcn tasar\u305 mlar\u305 n\u305  veya pazarlama stratejilerini iyile\u351 tirmek i\'e7in veriye dayal\u305  kararlar almas\u305 na yard\u305 mc\u305  olur.\
\

\fs36 \cf2 UCB ALGOR\uc0\u304 TMASI\
\

\fs28 \cf3 \'dcst G\'fcven S\uc0\u305 n\u305 r\u305  (Upper Confidence Bound - UCB) algoritmas\u305 , \'e7oklu se\'e7enekli bir problemde en iyi se\'e7imi yapma stratejisi olarak kullan\u305 l\u305 r. Bu strateji, belirsizlik i\'e7eren bir \'e7evrede en y\'fcksek beklenen \'f6d\'fcl\'fc (veya de\u287 eri) maksimize etmeyi ama\'e7lar. \u304 \u351 te UCB algoritmas\u305 n\u305 n temel \'e7al\u305 \u351 ma prensibi ve bir \'f6rnek:\
\
**\'c7al\uc0\u305 \u351 ma Prensibi:**\
\
UCB algoritmas\uc0\u305 , bir ajan\u305 n hangi se\'e7ene\u287 i (veya reklam\u305 ) se\'e7ece\u287 ini belirlemek i\'e7in g\'fcven s\u305 n\u305 rlar\u305 n\u305  kullan\u305 r. Ajan, her se\'e7enek i\'e7in bir tahmini ortalama \'f6d\'fcl ve bir g\'fcven aral\u305 \u287 \u305  hesaplar. G\'fcven aral\u305 \u287 \u305 , ajan\u305 n o se\'e7ene\u287 in ger\'e7ek ortalama \'f6d\'fcl\'fcn\'fcn bu aral\u305 k i\'e7inde oldu\u287 unu belirtir. UCB algoritmas\u305 , ajan\u305 n \u351 u ana kadar en az denemi\u351  veya en k\'f6t\'fc tahmin edilen se\'e7ene\u287 i se\'e7mesini sa\u287 lar.\
\
**\'d6rnek:**\
\
A\uc0\u351 a\u287 \u305 daki \'f6rnek, UCB algoritmas\u305 n\u305 n kullan\u305 ld\u305 \u287 \u305  bir reklam se\'e7imi senaryosunu g\'f6stermektedir. Diyelim ki bir online reklam platformunuz var ve 5 farkl\u305  reklam var. Her reklam\u305 n t\u305 klama oran\u305  belirsizdir ve ajan\u305 n hangi reklam\u305  se\'e7ece\u287 ini optimize etmek istiyoruz.\
\
- Reklam 1: 10% t\uc0\u305 klama oran\u305 \
- Reklam 2: 7% t\uc0\u305 klama oran\u305 \
- Reklam 3: 5% t\uc0\u305 klama oran\u305 \
- Reklam 4: 3% t\uc0\u305 klama oran\u305 \
- Reklam 5: 1% t\uc0\u305 klama oran\u305 \
\
Ajan, her reklam i\'e7in bir tahmini ortalama t\uc0\u305 klama oran\u305  ve bir g\'fcven aral\u305 \u287 \u305  hesaplar. \u304 lk ba\u351 ta g\'fcven aral\u305 \u287 \u305  geni\u351 tir \'e7\'fcnk\'fc hi\'e7bir reklam denenmemi\u351 tir. Ancak her t\u305 klama sonras\u305  g\'fcven aral\u305 \u287 \u305  daral\u305 r. UCB algoritmas\u305 , her se\'e7imde g\'fcven aral\u305 \u287 \u305 na dayal\u305  olarak bir reklam se\'e7er.\
\
\'d6rne\uc0\u287 in, ilk se\'e7imde ajan Reklam 1'i se\'e7ebilir. Bu se\'e7im sonras\u305 nda Reklam 1 i\'e7in g\'fcven aral\u305 \u287 \u305  daral\u305 r ve tahmini t\u305 klama oran\u305  g\'fcncellenir. Sonraki d\'f6nemlerde ajan di\u287 er reklamlar\u305  da deneyecek, ancak hangi reklam\u305 n en y\'fcksek UCB de\u287 erine sahip oldu\u287 unu g\'f6z \'f6n\'fcnde bulundurarak se\'e7imlerini optimize edecektir. Bu \u351 ekilde zamanla en iyi reklam\u305  belirlemeye \'e7al\u305 \u351 \u305 r.\
\
UCB algoritmas\uc0\u305 , reklamc\u305 l\u305 k, teklif verme stratejileri, online oyunlar ve envanter y\'f6netimi gibi bir\'e7ok uygulama alan\u305 nda kullan\u305 l\u305 r.\
\
\
\
\

\fs36 \cf4 RANDOM SAMPL\uc0\u304 NG
\fs28 \cf3 \
\
\
Rastgele \'f6rnekleme (random sampling), bir veri k\'fcmesinden rastgele bir alt \'f6rnek se\'e7me i\uc0\u351 lemidir. Bu y\'f6ntem, b\'fcy\'fck bir veri k\'fcmesinden temsil edici bir \'f6rnek elde etmek veya istatistiksel sonu\'e7lar \'e7\u305 karmak i\'e7in yayg\u305 n olarak kullan\u305 l\u305 r. Rastgele \'f6rnekleme, her bir \'f6\u287 e veya g\'f6zlem biriminin se\'e7ilme olas\u305 l\u305 \u287 \u305 n\u305 n e\u351 it oldu\u287 u bir y\'f6ntemi ifade eder.\
\
\'d6rne\uc0\u287 in, bir pazar ara\u351 t\u305 rmas\u305  yapmak istedi\u287 inizi d\'fc\u351 \'fcn\'fcn. Bu ara\u351 t\u305 rma i\'e7in n\'fcfusu temsil eden bir \'f6rneklem olu\u351 turman\u305 z gerekiyor. Bu durumda, n\'fcfusu temsil eden bir anketi rastgele se\'e7ilmi\u351  ki\u351 ilere uygulamak isteyebilirsiniz. \u304 \u351 te rastgele \'f6rnekleme ile ilgili \'f6rnek bir s\'fcre\'e7:\
\
1. **\'d6rneklem B\'fcy\'fckl\'fc\uc0\u287 \'fc Belirleme:** \u304 lk ad\u305 m, hangi kadar b\'fcy\'fck bir \'f6rneklem olu\u351 turmak istedi\u287 inizi belirlemektir. \'d6rneklem b\'fcy\'fckl\'fc\u287 \'fc, ara\u351 t\u305 rman\u305 z\u305 n amac\u305 na ve istatistiksel g\'fcc\'fcne ba\u287 l\u305  olarak de\u287 i\u351 ebilir.\
\
2. **Rastgele Se\'e7im:** Rastgele \'f6rnekleme i\uc0\u351 lemi, her bir ki\u351 inin veya \'f6\u287 enin se\'e7ilme olas\u305 l\u305 \u287 \u305 n\u305 n e\u351 it oldu\u287 u bir \u351 ekilde yap\u305 l\u305 r. Bu, her bireyin veya \'f6\u287 enin rastgele bir numara veya i\u351 aret ile etiketlendi\u287 i ve ard\u305 ndan rastgele se\'e7ilen numaralara veya i\u351 aretlere g\'f6re \'f6rneklemin olu\u351 turuldu\u287 u bir i\u351 lemi i\'e7erir.\
\
   \'d6rne\uc0\u287 in, bir n\'fcfusunuzu temsil etmek istiyorsan\u305 z, her bireyin bir liste numaras\u305  veya kimlik numaras\u305  olabilir ve bu numaralar\u305  kullanarak rastgele \'f6rneklem olu\u351 turabilirsiniz.\
\
3. **\'d6rneklemi Toplama:** Rastgele se\'e7ilen ki\uc0\u351 ileri veya \'f6\u287 eleri \'f6rnekleme alarak verilerinizi toplars\u305 n\u305 z. Bu veriler, daha sonra analiz veya sonu\'e7lar\u305 n\u305 z\u305  \'e7\u305 karmak i\'e7in kullan\u305 l\u305 r.\
\
4. **Analiz ve Sonu\'e7lar:** Elde edilen verileri analiz ederek, \'f6rnekleminizi temsil eden sonu\'e7lara ula\uc0\u351 abilirsiniz. Bu sonu\'e7lar, n\'fcfus hakk\u305 nda \'e7e\u351 itli istatistiksel sonu\'e7lar veya tahminler sa\u287 layabilir.\
\
Rastgele \'f6rnekleme, \'f6rneklem olu\uc0\u351 tururken \'f6zg\'fcll\'fc\u287 \'fc ve \'f6zg\'fcnl\'fc\u287 \'fc korur ve \'f6rneklemin n\'fcfusu temsil etme olas\u305 l\u305 \u287 \u305 n\u305  art\u305 r\u305 r. Bu y\'f6ntem, ara\u351 t\u305 rmac\u305 lar\u305 n rastgele bir \u351 ekilde se\'e7ilmi\u351  \'f6rneklerle daha g\'fcvenilir sonu\'e7lar elde etmelerine yard\u305 mc\u305  olur.\
\
}